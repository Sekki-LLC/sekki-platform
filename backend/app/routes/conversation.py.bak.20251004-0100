from __future__ import annotations
import os, uuid
from flask import Blueprint, request, jsonify, current_app
from anthropic import Anthropic

conversation_bp = Blueprint("conversation", __name__)

ANTHROPIC_MODEL = os.getenv("ANTHROPIC_MODEL", "claude-3-5-sonnet-latest")
_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

DEFAULT_SYSTEM_PROMPT = (
    "You facilitate a natural discovery chat to build a Market IQ scorecard. "
    "Ask one concise question at a time. Acknowledge prior answers; do not restart. "
    "Do not repeat a question verbatim. If the user asks you something, answer briefly before your next question. "
    "Be friendly, crisp, and keep momentum."
)

def _norm(s: str) -> str:
    return " ".join((s or "").lower().split())

def _is_rigid(text: str) -> bool:
    a = _norm(text)
    return any(kw in a for kw in (
        "let's start with the primary goal",
        "what is the main objective you aim to achieve",
        "i'll ask you a series of questions",
    ))

def _is_dup(new: str, prev: str) -> bool:
    a, b = _norm(new), _norm(prev)
    return bool(a and b and a == b)

def _readiness(history):  # history: list[{role,content}]
    users = sum(1 for m in history if m.get("role") == "user" and _norm(m.get("content","")))
    return min(100, round((users/6)*100))

def _fmt(history):
    out=[]
    for m in history:
        role = "user" if m.get("role")=="user" else "assistant"
        content = m.get("content","")
        if content:
            out.append({"role": role, "content": content})
    return out

def _ask(system_prompt, history, temperature=0.2, max_tokens=400) -> str:
    try:
        resp = _client.messages.create(
            model=ANTHROPIC_MODEL,
            system=system_prompt or DEFAULT_SYSTEM_PROMPT,
            temperature=temperature,
            max_tokens=max_tokens,
            messages=_fmt(history),
        )
        try:
            return (resp.content[0].text or "").strip()
        except Exception:
            return ""
    except Exception as e:
        current_app.logger.exception("anthropic_error: %s", e)
        return ""

@conversation_bp.route("/start", methods=["POST"])
def start():
    p = request.get_json(silent=True) or {}
    desc = (p.get("description") or "").strip() or "Let's begin."
    system = p.get("systemPrompt") or DEFAULT_SYSTEM_PROMPT

    history = [{"role":"user","content":desc}]
    reply = _ask(system, history)
    if _is_rigid(reply):
        history.append({"role":"user","content":"Please continue without repeating; ask one focused follow-up."})
        reply = _ask(system, history, temperature=0.1)
    if not reply:
        reply = "Got it. Who is this for and what outcome matters most?"

    return jsonify({
        "session_id": f"conv_{uuid.uuid4().hex[:12]}",
        "message": reply,
        "readiness_score": _readiness(history),
        "status": "gathering_info",
    })

@conversation_bp.route("/continue", methods=["POST"])
def cont():
    p = request.get_json(silent=True) or {}
    sid = p.get("session_id") or f"conv_{uuid.uuid4().hex[:12]}"
    user_msg = (p.get("message") or p.get("user_message") or "").strip()
    system = p.get("systemPrompt") or DEFAULT_SYSTEM_PROMPT
    history = p.get("conversation_history") or []

    if user_msg:
        if not history or history[-1].get("role") != "user" or _norm(history[-1].get("content","")) != _norm(user_msg):
            history.append({"role":"user","content":user_msg})

    reply = _ask(system, history)
    last_ai = next((m for m in reversed(history) if m.get("role")=="assistant"), None)
    if _is_rigid(reply) or (last_ai and _is_dup(reply, last_ai.get("content",""))):
        history.append({"role":"user","content":"Your last reply repeated earlier questions. Please respond to my latest answer directly; ask one new follow-up."})
        reply = _ask(system, history, temperature=0.1)
    if not reply:
        reply = "Understood. Briefly: whoâ€™s the target customer and what budget/timeline are you aiming for?"

    return jsonify({
        "session_id": sid,
        "message": reply,
        "readiness_score": _readiness(history),
        "status": "gathering_info",
    })
