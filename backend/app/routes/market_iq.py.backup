from __future__ import annotations
import os, json, time, uuid, sqlite3, re
from typing import Dict, Any, Optional, List
from flask import Blueprint, request, jsonify, current_app

# httpx is optional; if missing we silently fall back to a non-LLM question
try:
    import httpx  # type: ignore
except Exception:  # pragma: no cover
    httpx = None

market_iq_bp = Blueprint("market_iq", __name__, url_prefix="/api/market-iq")

# ---------- storage ----------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))  # .../backend
RUNTIME_DIR = os.path.join(BASE_DIR, "runtime")
os.makedirs(RUNTIME_DIR, exist_ok=True)
DB_PATH = os.environ.get("MIQ_DB_PATH", os.path.join(RUNTIME_DIR, "miq_sessions.sqlite3"))

def _db():
    con = sqlite3.connect(DB_PATH)
    con.row_factory = sqlite3.Row
    con.execute("""
    CREATE TABLE IF NOT EXISTS sessions (
      id TEXT PRIMARY KEY,
      description TEXT NOT NULL,
      answers_json TEXT NOT NULL,
      remaining_json TEXT NOT NULL,
      last_field TEXT,
      answered_q INTEGER NOT NULL,
      total_q INTEGER NOT NULL,
      created_at INTEGER NOT NULL
    );
    """)
    return con

def _new_id() -> str:
    return f"miq_{uuid.uuid4().hex[:10]}"

# Coverage map: fields we want to collect (LLM writes the wording)
FIELD_ORDER: List[str] = [
    "primary_goal", "target_customer", "problem", "solution",
    "differentiators", "market_size", "pricing_model", "budget",
    "timeline", "kpi", "risks", "channels",
    "team", "constraints", "data_availability", "compliance",
]

def _load(sid: str) -> Optional[Dict[str, Any]]:
    with _db() as con:
        row = con.execute("SELECT * FROM sessions WHERE id=?", (sid,)).fetchone()
        if not row:
            return None
        return {
            "id": row["id"],
            "description": row["description"],
            "answers": json.loads(row["answers_json"] or "{}"),
            "remaining": json.loads(row["remaining_json"] or "[]"),
            "last_field": row["last_field"],
            "answered_q": int(row["answered_q"]),
            "total_q": int(row["total_q"]),
            "created_at": int(row["created_at"]),
        }

def _save(sess: Dict[str, Any]) -> None:
    with _db() as con:
        con.execute("""
        INSERT INTO sessions (id, description, answers_json, remaining_json, last_field, answered_q, total_q, created_at)
        VALUES (?,?,?,?,?,?,?,?)
        ON CONFLICT(id) DO UPDATE SET
          description=excluded.description,
          answers_json=excluded.answers_json,
          remaining_json=excluded.remaining_json,
          last_field=excluded.last_field,
          answered_q=excluded.answered_q,
          total_q=excluded.total_q
        """, (
            sess["id"],
            sess["description"],
            json.dumps(sess.get("answers", {})),
            json.dumps(sess.get("remaining", [])),
            sess.get("last_field"),
            int(sess.get("answered_q", 0)),
            int(sess.get("total_q", len(FIELD_ORDER))),
            int(sess.get("created_at", int(time.time()))),
        ))
        con.commit()

# ---------- LLM helpers ----------
def _bool_env(name: str, default=False) -> bool:
    v = os.environ.get(name, "").strip().lower()
    if v in ("1","true","yes","y","on"): return True
    if v in ("0","false","no","n","off"): return False
    return bool(default)

def llm_enabled() -> bool:
    return _bool_env("MIQ_USE_LLM", False) and bool(os.environ.get("OPENAI_API_KEY")) and (httpx is not None)

def _clean_text(s: str) -> str:
    s = re.sub(r"\r\n?", "\n", s or "").strip()
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s

SYSTEM_PROMPT = """
You are a senior go-to-market analyst conducting a conversational intake to score project viability.
Rules:
- Ask ONE clear, natural question at a time based on what is still unknown.
- Never repeat the same question. Acknowledge prior info briefly.
- If the user is unsure, suggest 2–3 pragmatic options to choose from.
- Keep replies concise (2–5 sentences). End every turn with exactly one question.
- Avoid bullet formatting unless listing options.
- When you have enough info to score, say exactly:
  "I have enough to score this. Type 'finish' to see your score."
  Then ask one short confirmation question if helpful.
"""

def _llm_next_question(description: str, answers: Dict[str, Any], remaining: List[str], last_user_text: str = "") -> str:
    if not llm_enabled():
        hint = (remaining[0] if remaining else "anything important we missed").replace("_", " ")
        return f"Got it. To round this out, could you share more about your {hint}?"

    key = os.environ["OPENAI_API_KEY"].strip()
    model = os.environ.get("MIQ_MODEL", "gpt-4o").strip()
    try:
        temp = float(os.environ.get("MIQ_TEMPERATURE", "0.2"))
    except Exception:
        temp = 0.2

    messages = [
        {"role":"system","content":_clean_text(SYSTEM_PROMPT)},
        {"role":"user","content":_clean_text(f"Project description: {description or 'n/a'}")},
        {"role":"user","content":_clean_text(f"Known answers (JSON): {json.dumps(answers, ensure_ascii=False)}")},
        {"role":"user","content":_clean_text(f"Still need to cover (ordered field keys): {remaining}")},
    ]
    if last_user_text:
        messages.append({"role":"user","content":_clean_text(f"User just said: {last_user_text}")})

    try:
        with httpx.Client(timeout=30.0) as client:  # type: ignore
            r = client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
                json={"model": model, "temperature": temp, "messages": messages, "max_tokens": 300},
            )
        r.raise_for_status()
        data = r.json()
        text = ((data.get("choices") or [{}])[0].get("message") or {}).get("content") or ""
        text = _clean_text(text) or "Could you share a bit more detail so I can score this accurately?"
        if "?" not in text:
            text = text.rstrip(".") + "?"
        return text
    except Exception as e:
        current_app.logger.error("LLM error: %s", e)
        hint = (remaining[0] if remaining else "anything important we missed").replace("_", " ")
        return f"Thanks. One more thing—what can you tell me about your {hint}?"

def _next_field(remaining: List[str]) -> Optional[str]:
    return remaining[0] if remaining else None

def _store_answer(sess: Dict[str,Any], text_answer: str) -> None:
    answers = dict(sess.get("answers") or {})
    f = sess.get("last_field")
    if not f:
        # very light heuristic
        lower = (text_answer or "").lower()
        for k in FIELD_ORDER:
            lbl = k.replace("_", " ")
            if lbl in lower or k in lower:
                f = k
                break
        if not f:
            f = _next_field(list(sess.get("remaining") or [])) or "misc"
    answers[f] = text_answer
    sess["answers"] = answers
    rem = list(sess.get("remaining") or [])
    if f in rem:
        rem.remove(f)
    sess["remaining"] = rem
    sess["answered_q"] = int(sess.get("answered_q", 0)) + 1

# ---------- endpoints ----------
@market_iq_bp.route("/intake/start", methods=["POST"])
def intake_start():
    try:
        j = request.get_json(silent=True) or {}
        desc = (j.get("description") or "").strip()
        sess = {
            "id": _new_id(),
            "description": desc,
            "answers": {},
            "remaining": FIELD_ORDER.copy(),
            "last_field": None,
            "answered_q": 0,
            "total_q": len(FIELD_ORDER),
            "created_at": int(time.time()),
        }
        f = _next_field(sess["remaining"])
        q = _llm_next_question(desc, sess["answers"], sess["remaining"], last_user_text="")
        sess["last_field"] = f
        _save(sess)
        return jsonify({
            "analysis_id": sess["id"],
            "field": f,
            "question": q,
            "answered": sess["answered_q"],
            "total_questions": sess["total_q"],
        }), 200
    except Exception as e:
        current_app.logger.exception("intake_start_failed")
        return jsonify({"error":"intake_start_failed","details":str(e)}), 500

@market_iq_bp.route("/intake/answer", methods=["POST"])
def intake_answer():
    try:
        j = request.get_json(silent=True) or {}
        sid = j.get("analysis_id")
        answer = (j.get("answer") or "").strip()
        finalize = bool(j.get("finalize"))
        sess = _load(sid) if sid else None
        if not sess:
            return jsonify({"error":"unknown_analysis_id"}), 400

        if answer:
            _store_answer(sess, answer)
            _save(sess)

        have_enough = sess["answered_q"] >= 8  # heuristic threshold
        if finalize or have_enough:
            return jsonify({
                "complete": True,
                "analysis_context": {
                    "description": sess["description"],
                    "answers": sess["answers"],
                },
                "answered": sess["answered_q"],
                "total_questions": sess["total_q"],
                "message": "Type 'finish' or call /analyze with description+answers to get the score."
            }), 200

        f = _next_field(sess["remaining"])
        q = _llm_next_question(sess["description"], sess["answers"], sess["remaining"], last_user_text=answer)
        sess["last_field"] = f
        _save(sess)
        return jsonify({
            "complete": False,
            "next_field": f,
            "next_question": q,
            "answered": sess["answered_q"],
            "total_questions": sess["total_q"],
        }), 200
    except Exception as e:
        current_app.logger.exception("intake_answer_failed")
        return jsonify({"error":"intake_answer_failed","details":str(e)}), 500

@market_iq_bp.route("/analyze", methods=["POST"])
def analyze():
    try:
        j = request.get_json(silent=True) or {}
        description = (j.get("description") or "").strip()
        answers = j.get("answers") or {}

        covered = sum(1 for k in FIELD_ORDER if answers.get(k))
        base = 40 + covered * 3  # placeholder 40..88
        score = max(10, min(99, base))
        summary = ("Preliminary Market IQ summary based on your inputs. "
                   "Replace this with your production scoring pipeline.")
        component_scores = {
            "market": min(99, 50 + 3*covered),
            "team": min(99, 45 + 2*covered),
            "economics": min(99, 40 + 3*covered),
            "risk": max(1, 90 - 2*covered),
        }
        return jsonify({
            "market_iq_score": score,
            "summary": summary,
            "component_scores": component_scores,
            "answers": answers,
            "description": description,
        }), 200
    except Exception as e:
        current_app.logger.exception("analyze_failed")
        return jsonify({"error":"analyze_failed","details":str(e)}), 500

@market_iq_bp.route("/scenario", methods=["POST"])
def scenario():
    try:
        j = request.get_json(silent=True) or {}
        analysis = j.get("analysis_result") or {}
        changes = j.get("changes") or {}
        out = dict(analysis)
        if "market_iq_score" in out and isinstance(changes.get("delta"), (int, float)):
            out["market_iq_score"] = int(max(1, min(99, out["market_iq_score"] + int(changes["delta"]))))
        return jsonify({"scenario_applied": True, "analysis_result": out}), 200
    except Exception as e:
        current_app.logger.exception("scenario_failed")
        return jsonify({"error":"scenario_failed","details":str(e)}), 500
