from flask import Blueprint, request, jsonify
import os, json, sqlite3, uuid
from datetime import datetime
from contextlib import contextmanager
from dotenv import load_dotenv

# ----- env & OpenAI client -----
load_dotenv()
from openai import OpenAI
def _client():
    return OpenAI()

MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

market_iq_bp = Blueprint("market_iq", __name__, url_prefix="/api/market-iq")

# ----- SQLite persistence -----
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
DB_PATH = os.getenv("MARKET_IQ_DB", os.path.join(BASE_DIR, "market_iq.db"))
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

def _dict_factory(cursor, row):
    return {col[0]: row[idx] for idx, col in enumerate(cursor.description)}

@contextmanager
def db():
    con = sqlite3.connect(DB_PATH, check_same_thread=False)
    con.row_factory = _dict_factory
    try:
        yield con
        con.commit()
    finally:
        con.close()

def init_db():
    with db() as con:
        con.execute("""
        CREATE TABLE IF NOT EXISTS sessions(
          id TEXT PRIMARY KEY,
          description TEXT NOT NULL,
          answers_json TEXT NOT NULL,
          last_field TEXT,
          last_question TEXT,
          total_q INTEGER NOT NULL,
          answered_q INTEGER NOT NULL,
          status TEXT NOT NULL,
          created_at TEXT NOT NULL
        )
        """)
init_db()

# ===== Adaptive intake configuration =====
# (We track fields but we DON'T hardcode the question text.)
REQUIRED_FIELDS = [
    "primary_goal",
    "project_type",
    "target_customer",
    "market_geography",
    "market_size",
    "budget_total",
    "runway_months",
    "timeline_target",
    "revenue_model",
    "current_stage",
    "team",
    "competitors",
    "gtm_channels",
    "unit_economics",
    "key_risks",
    "constraints",
]
TOTAL_Q = len(REQUIRED_FIELDS)

def _now():
    return datetime.utcnow().isoformat() + "Z"

def _load_session(con, sid):
    row = con.execute("SELECT * FROM sessions WHERE id=?", (sid,)).fetchone()
    if not row: return None
    row["answers"] = json.loads(row.get("answers_json") or "{}")
    return row

def _save_session(con, sess):
    data = dict(sess)
    data["answers_json"] = json.dumps(sess.get("answers", {}), ensure_ascii=False)
    cols = ("id","description","answers_json","last_field","last_question",
            "total_q","answered_q","status","created_at")
    vals = tuple(data.get(k) for k in cols)
    con.execute("""
      INSERT INTO sessions(id,description,answers_json,last_field,last_question,total_q,answered_q,status,created_at)
      VALUES(?,?,?,?,?,?,?,?,?)
      ON CONFLICT(id) DO UPDATE SET
        description=excluded.description,
        answers_json=excluded.answers_json,
        last_field=excluded.last_field,
        last_question=excluded.last_question,
        total_q=excluded.total_q,
        answered_q=excluded.answered_q,
        status=excluded.status
    """, vals)

def _score_with_llm(description, answers):
    sys = (
      "You are Market IQ. Score initiatives across finance, operations, market, execution. "
      "Output strict JSON:\n"
      "{"
      '"market_iq_score": int, "score_category": "Poor|Fair|Good|Strong|Excellent", '
      '"component_scores":{"financial_health":int,"operational_efficiency":int,"market_position":int,"execution_readiness":int},'
      '"financial_impact":{"ebitda_at_risk":str,"potential_loss":str,"roi_opportunity":str,"projected_ebitda":str,"time_to_market_impact":str},'
      '"key_insights":[str...],'
      '"top_risks":[{"risk":str,"impact":str,"mitigation":str}...],'
      '"recommendations":[{"action":str,"expected_impact":str,"effort":"Low|Medium|High","timeline":str}...]'
      "}"
    )
    user = json.dumps({"project_description": description, "answers": answers}, ensure_ascii=False)
    resp = _client().chat.completions.create(
        model=MODEL,
        temperature=0.2,
        response_format={"type":"json_object"},
        messages=[{"role":"system","content":sys},{"role":"user","content":user}]
    )
    return json.loads(resp.choices[0].message.content)

# Import adaptive helpers
from app.miq_qgen import propose_next_question, extract_fields

def _remaining_fields(answers: dict):
    return [f for f in REQUIRED_FIELDS if f not in (answers or {})]

@market_iq_bp.route("/intake/start", methods=["POST"])
def intake_start():
    try:
        data = request.get_json(force=True) or {}
        description = (data.get("description") or data.get("project_description") or "").strip()
        if not description:
            return jsonify({"error":"missing_description"}), 400

        sid = "miq_" + uuid.uuid4().hex[:10]
        answers = {}

        # Ask the first best question (LLM chooses which field to fill first)
        rem = _remaining_fields(answers)
        nxt = propose_next_question(description, answers, rem)

        with db() as con:
            sess = {
                "id": sid, "description": description, "answers": answers,
                "last_field": nxt["field"], "last_question": nxt["question"],
                "total_q": TOTAL_Q, "answered_q": 0, "status": "intake",
                "created_at": _now()
            }
            _save_session(con, sess)

        return jsonify({
            "analysis_id": sid,
            "field": nxt["field"],
            "question": nxt["question"],
            "answered": 0,
            "total_questions": TOTAL_Q
        })
    except Exception as e:
        return jsonify({"error":"intake_start_failed","details":str(e)}), 500

@market_iq_bp.route("/intake/answer", methods=["POST"])
def intake_answer():
    try:
        data = request.get_json(force=True) or {}
        sid = data.get("analysis_id")
        field = data.get("field")   # which field this answer belongs to (frontend sends it)
        answer_text = data.get("answer")

        if not sid or field is None or answer_text is None:
            return jsonify({"error":"missing_params"}), 400

        with db() as con:
            sess = _load_session(con, sid)
            if not sess: return jsonify({"error":"unknown_analysis_id"}), 404

            # Save the answer for the specified field
            if field not in sess["answers"]:
                sess["answered_q"] += 1
            sess["answers"][field] = answer_text

            # Try to auto-fill other fields from this freeform answer/description
            rem_before = _remaining_fields(sess["answers"])
            inferred = extract_fields(sess["description"], sess["answers"], answer_text, rem_before)
            for k, v in (inferred or {}).items():
                if k not in sess["answers"] and v:
                    sess["answers"][k] = v
                    sess["answered_q"] += 1

            # Complete?
            if sess["answered_q"] >= sess["total_q"]:
                try:
                    analysis = _score_with_llm(sess["description"], sess["answers"])
                except Exception as e:
                    return jsonify({"error":"llm_unavailable","details":str(e)}), 503

                sess["status"] = "complete"
                _save_session(con, sess)

                analysis["analysis_id"] = sid
                analysis["timestamp"] = _now()
                analysis["answers"] = sess["answers"]
                analysis["description"] = sess["description"]
                return jsonify({"complete": True, "analysis_result": analysis})

            # Otherwise, pick the next best question dynamically
            remaining = _remaining_fields(sess["answers"])
            nxt = propose_next_question(sess["description"], sess["answers"], remaining)
            sess["last_field"] = nxt["field"]
            sess["last_question"] = nxt["question"]
            _save_session(con, sess)

            return jsonify({
                "complete": False,
                "next_field": nxt["field"],
                "next_question": nxt["question"],
                "answered": sess["answered_q"],
                "total_questions": sess["total_q"]
            })
    except Exception as e:
        return jsonify({"error":"intake_answer_failed","details":str(e)}), 500

@market_iq_bp.route("/scenario", methods=["POST"])
def scenario():
    try:
        data = request.get_json(force=True) or {}
        base = data.get("analysis_result") or {}
        changes = data.get("changes") or {}
        description = base.get("description") or "Scenario"
        answers = base.get("answers") or {}
        answers.update(changes)
        try:
            analysis = _score_with_llm(description, answers)
        except Exception as e:
            return jsonify({"error":"llm_unavailable","details":str(e)}), 503
        analysis["scenario_from"] = base.get("analysis_id")
        analysis["analysis_id"] = "miq_" + uuid.uuid4().hex[:10]
        analysis["timestamp"] = _now()
        analysis["answers"] = answers
        analysis["description"] = description
        return jsonify(analysis)
    except Exception as e:
        return jsonify({"error":"scenario_failed","details":str(e)}), 500

@market_iq_bp.route("/analyze", methods=["POST"])
def analyze_shim():
    try:
        data = request.get_json(force=True) or {}
        description = (data.get("description") or data.get("project_description") or "").strip()
        if not description:
            return jsonify({"error":"missing_description"}), 400
        sid = "miq_" + uuid.uuid4().hex[:10]
        with db() as con:
            _save_session(con, {
                "id": sid, "description": description, "answers": {},
                "last_field": None, "last_question": None,
                "total_q": TOTAL_Q, "answered_q": 0, "status": "intake",
                "created_at": _now()
            })
        # Keep behavior aligned with start: immediately return first question
        from app.miq_qgen import propose_next_question
        nxt = propose_next_question(description, {}, REQUIRED_FIELDS)
        with db() as con:
            sess = _load_session(con, sid)
            sess["last_field"] = nxt["field"]
            sess["last_question"] = nxt["question"]
            _save_session(con, sess)
        return jsonify({
            "analysis_id": sid,
            "field": nxt["field"],
            "question": nxt["question"],
            "answered": 0,
            "total_questions": TOTAL_Q
        })
    except Exception as e:
        return jsonify({"error":"analyze_failed","details":str(e)}), 500
