from flask import Blueprint, request, jsonify
import os, time, uuid, json
from datetime import datetime

market_iq_bp = Blueprint('market_iq', __name__, url_prefix='/api/market-iq')

# --- simple in-memory session store (ok for single process) ---
_SESS = {}  # analysis_id -> {"description": str, "created": ts}

# --- OpenAI client (optional) ---
_CLIENT = None
def _get_client():
    global _CLIENT
    if _CLIENT is not None:
        return _CLIENT
    try:
        from openai import OpenAI
        _CLIENT = OpenAI()
        return _CLIENT
    except Exception:
        return None

def _call_llm_json(system_prompt: str, user_prompt: str, model=None, temperature=0.2):
    client = _get_client()
    if not client:
        return None
    mdl = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    try:
        resp = client.chat.completions.create(
            model=mdl,
            response_format={"type": "json_object"},
            temperature=temperature,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        content = resp.choices[0].message.content
        return json.loads(content)
    except Exception:
        return None

def _fallback_result(description: str, analysis_id: str):
    # deterministic mock so FE always has something even if LLM is unavailable
    base = 70 + (hash(description) % 11)  # 70–80
    cat = "Good Performance" if base < 78 else "Strong Performance"
    result = {
        "market_iq_score": base,
        "score_category": cat,
        "component_scores": {
            "financial_health": min(95, base + 8),
            "operational_efficiency": max(55, base - 11),
            "market_position": base + 3,
            "execution_readiness": max(60, base - 6),
        },
        "financial_impact": {
            "ebitda_at_risk": "15%",
            "potential_loss": "$300K",
            "roi_opportunity": "8%",
            "projected_ebitda": "$2.1M",
            "time_to_market_impact": "3 months delay = $450K revenue loss"
        },
        "key_insights": [
            "Financial fundamentals are solid; runway supports near-term execution.",
            "Operational bottlenecks create EBITDA leakage risk if unaddressed.",
            "Market position is competitive; faster launch improves share capture."
        ],
        "top_risks": [
            {"risk": "Time-to-market slip vs. peers", "impact": "$450K revenue delay", "mitigation": "Parallelize QA and adopt MVP launch"},
            {"risk": "Process inefficiency", "impact": "$300K EBITDA reduction", "mitigation": "Lean improvements and automation"}
        ],
        "recommendations": [
            {"action": "Accelerate MVP by 8–10 weeks", "expected_impact": "$450K revenue acceleration", "effort": "Medium", "timeline": "6–8 weeks"},
            {"action": "Standardize key processes", "expected_impact": "15% EBITDA lift", "effort": "High", "timeline": "3–6 months"}
        ],
        "analysis_id": analysis_id,
        "timestamp": datetime.utcnow().isoformat() + "Z"
    }
    return result

def _score_with_llm(description: str, analysis_id: str):
    sys = (
        "You are MarketIQ, a finance & ops analyst. Return ONLY JSON with these keys:\n"
        "market_iq_score (0-100 integer), score_category (One of: Weak, Fair, Good, Strong, Excellent),\n"
        "component_scores {financial_health, operational_efficiency, market_position, execution_readiness},\n"
        "financial_impact {ebitda_at_risk (percent string), potential_loss ($ string), roi_opportunity (percent string), projected_ebitda ($ string), time_to_market_impact (string)},\n"
        "key_insights [3 concise bullets],\n"
        "top_risks [{risk, impact, mitigation}],\n"
        "recommendations [{action, expected_impact, effort, timeline}],\n"
        "analysis_id (preserve input id), timestamp (ISO8601).\n"
        "Be concrete and businesslike; keep strings concise."
    )
    usr = json.dumps({
        "analysis_id": analysis_id,
        "project_description": description
    }, ensure_ascii=False)
    data = _call_llm_json(sys, usr)
    if not data:
        return _fallback_result(description, analysis_id)

    # Ensure required keys exist; fill minimal defaults if missing
    data.setdefault("analysis_id", analysis_id)
    data.setdefault("timestamp", datetime.utcnow().isoformat() + "Z")
    req_keys = ["market_iq_score","score_category","component_scores","financial_impact",
                "key_insights","top_risks","recommendations"]
    for k in req_keys:
        if k not in data:
            return _fallback_result(description, analysis_id)
    return data

@market_iq_bp.route('/analyze', methods=['POST'])
def analyze():
    """
    Accepts: { description: str }
    Returns: full analysis JSON used by the FE summary/score dashboard.
    """
    payload = request.get_json(silent=True) or {}
    description = payload.get("description") or payload.get("project_description")
    if not description:
        return jsonify({"error": "description is required"}), 400

    analysis_id = "miq_" + uuid.uuid4().hex[:10]
    _SESS[analysis_id] = {"description": description, "created": time.time()}

    result = _score_with_llm(description, analysis_id)
    return jsonify(result), 200

@market_iq_bp.route('/chat', methods=['POST'])
def chat():
    """
    Accepts: { message: str, analysis_context: {...} }
    Returns: { response: str }
    """
    payload = request.get_json(silent=True) or {}
    message = payload.get("message", "").strip()
    ctx = payload.get("analysis_context") or {}
    if not message:
        return jsonify({"error": "message is required"}), 400

    # Try LLM first
    client = _get_client()
    if client:
        try:
            sys = (
                "You are MarketIQ, a pragmatic strategy & finance copilot. "
                "Use the provided analysis context to answer in clear, actionable bullets. "
                "Be specific with numbers and timelines when possible."
            )
            user = "User question:\n{}\n\nAnalysis context JSON:\n{}".format(
                message, json.dumps(ctx, ensure_ascii=False)
            )
            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                temperature=0.3,
                messages=[{"role":"system","content":sys},{"role":"user","content":user}]
            )
            content = resp.choices[0].message.content.strip()
            return jsonify({"response": content}), 200
        except Exception:
            pass

    # Fallback deterministic answer
    score = ctx.get("market_iq_score", 72)
    fallback = (
        f"Here’s a focused take based on your Market IQ score of {score}:\n\n"
        "• **Immediate EBITDA protection (this quarter):** Standardize 2–3 highest-volume processes; target 12–18% cycle-time cut.\n"
        "• **Accelerate launch:** Convert to MVP + parallel QA to pull in the date by 8–10 weeks.\n"
        "• **Guardrails:** Weekly KPI review (throughput, defect rate, burn), go/no-go gates per sprint.\n\n"
        "Want a 6-week action plan broken into owners, costs, and KPIs?"
    )
    return jsonify({"response": fallback}), 200
