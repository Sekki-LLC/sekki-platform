from flask import Blueprint, request, jsonify
import os, json, uuid, time, sqlite3
from datetime import datetime
from contextlib import contextmanager

market_iq_bp = Blueprint("market_iq", __name__, url_prefix="/api/market-iq")

# ---------------------- Storage (SQLite) ----------------------
DB_PATH = os.getenv("MARKET_IQ_DB", os.path.join(os.path.dirname(__file__), "../../market_iq.db"))

def _dict_factory(cursor, row):
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d

@contextmanager
def db():
    con = sqlite3.connect(DB_PATH, check_same_thread=False)
    con.row_factory = _dict_factory
    try:
        yield con
        con.commit()
    finally:
        con.close()

def init_db():
    with db() as con:
        cur = con.cursor()
        cur.execute("""
        CREATE TABLE IF NOT EXISTS sessions(
          id TEXT PRIMARY KEY,
          description TEXT NOT NULL,
          created_at TEXT NOT NULL,
          status TEXT NOT NULL default 'intake'
        )""")
        cur.execute("""
        CREATE TABLE IF NOT EXISTS qa(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          session_id TEXT NOT NULL,
          field TEXT,
          question TEXT NOT NULL,
          answer TEXT NOT NULL,
          created_at TEXT NOT NULL,
          FOREIGN KEY(session_id) REFERENCES sessions(id)
        )""")
        cur.execute("""
        CREATE TABLE IF NOT EXISTS results(
          session_id TEXT PRIMARY KEY,
          payload_json TEXT NOT NULL,
          created_at TEXT NOT NULL,
          FOREIGN KEY(session_id) REFERENCES sessions(id)
        )""")

init_db()

# ---------------------- OpenAI client ----------------------
_CLIENT = None
def _get_client():
    global _CLIENT
    if _CLIENT is not None:
        return _CLIENT
    try:
        from openai import OpenAI
        _CLIENT = OpenAI()
        return _CLIENT
    except Exception:
        return None

def _chat_json(system_prompt, user_payload, model=None, temperature=0.2):
    client = _get_client()
    if not client:
        raise RuntimeError("LLM unavailable")
    mdl = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    resp = client.chat.completions.create(
        model=mdl,
        temperature=temperature,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)}
        ]
    )
    txt = resp.choices[0].message.content
    return json.loads(txt)

# ---------------------- Intake logic ----------------------
# Fields we want to capture (explicit = high precision)
REQUIRED_FIELDS = [
    "primary_goal",       # revenue | EBITDA | market_share | other
    "project_type",       # product | feature | service | ops_program | other
    "target_customer",    # ICP + segment
    "market_geography",   # regions/countries
    "market_size",        # numeric or range (TAM/SAM/SOM if known)
    "budget_total",       # total budget available
    "runway_months",      # months
    "timeline_target",    # desired GA/MVP date or months
    "revenue_model",      # pricing strategy, ARPU/ACV if B2B
    "current_stage",      # idea | mvp | beta | ga | scale
    "team",               # size/roles/partners
    "key_risks",          # list
    "competitors",        # list + pos/diff
    "differentiators",    # short bullets
    "gtm_channels",       # sales/marketing channels
    "unit_economics",     # CAC, LTV, gross_margin if known
    "constraints"         # tech/regulatory/ops constraints
]

INTAKE_SYS = (
    "You are MarketIQ-Collector. Goal: gather the MINIMUM questions to compute a precise MarketIQ score. "
    "You have a fixed field set called REQUIRED_FIELDS. Given description and prior Q&A, output ONLY JSON: "
    "{ enough: boolean, missing_fields: string[], next: { field: string|null, question: string|null } }. "
    "Rules: (1) Ask exactly one concrete, unambiguous question when enough=false. "
    "(2) Map your question to the most relevant REQUIRED_FIELDS key in 'field'. "
    "(3) Prefer numeric/time-bound ask (budget $, months, %). "
    f"(4) REQUIRED_FIELDS = {REQUIRED_FIELDS}."
)

SCORE_SYS = (
    "You are MarketIQ-Scorer, a finance/operations analyst. Return ONLY JSON with this schema: {"
    " market_iq_score: integer(0..100),"
    " score_category: enum['Weak','Fair','Good','Strong','Excellent'],"
    " component_scores: { financial_health:int, operational_efficiency:int, market_position:int, execution_readiness:int },"
    " financial_impact: { ebitda_at_risk:string, potential_loss:string, roi_opportunity:string, projected_ebitda:string, time_to_market_impact:string },"
    " key_insights: string[3..6],"
    " top_risks: {risk:string, impact:string, mitigation:string}[],"
    " recommendations: {action:string, expected_impact:string, effort:string, timeline:string}[],"
    " analysis_id:string, timestamp:string ISO8601 }."
    " Be concise, numeric where possible, and internally consistent."
)

def _validate_score(payload: dict):
    # Minimal strict validation; raise on any inconsistency (no mock generation)
    required_top = ["market_iq_score","score_category","component_scores","financial_impact",
                    "key_insights","top_risks","recommendations","analysis_id","timestamp"]
    for k in required_top:
        if k not in payload:
            raise ValueError(f"missing {k}")
    s = payload["market_iq_score"]
    if not isinstance(s, int) or not (0 <= s <= 100):
        raise ValueError("market_iq_score must be int 0..100")
    cats = {"Weak","Fair","Good","Strong","Excellent"}
    if payload["score_category"] not in cats:
        raise ValueError("invalid score_category")
    for comp in ["financial_health","operational_efficiency","market_position","execution_readiness"]:
        v = payload["component_scores"].get(comp)
        if not isinstance(v, int) or not (0 <= v <= 100):
            raise ValueError(f"component {comp} invalid")

def _session_row(session_id):
    with db() as con:
        r = con.execute("SELECT * FROM sessions WHERE id=?", (session_id,)).fetchone()
        return r

def _qa_list(session_id):
    with db() as con:
        rows = con.execute("SELECT field, question, answer FROM qa WHERE session_id=? ORDER BY id ASC", (session_id,)).fetchall()
        return rows or []

def _first_missing_fields(given_rows):
    answered = {row["field"] for row in given_rows if row["field"]}
    return [f for f in REQUIRED_FIELDS if f not in answered]

@market_iq_bp.route("/intake/start", methods=["POST"])
def intake_start():
    payload = request.get_json(silent=True) or {}
    description = payload.get("description") or payload.get("project_description")
    if not description:
        return jsonify({"error": "description is required"}), 400
    session_id = "miq_" + uuid.uuid4().hex[:12]
    with db() as con:
        con.execute("INSERT INTO sessions(id, description, created_at, status) VALUES (?,?,?,?)",
                    (session_id, description, datetime.utcnow().isoformat()+"Z", "intake"))
    # ask first LLM question
    try:
        out = _chat_json(INTAKE_SYS, {"description": description, "qa": [], "required_fields": REQUIRED_FIELDS})
    except Exception as e:
        return jsonify({"error":"llm_unavailable", "details": str(e)}), 503
    if not isinstance(out, dict) or "next" not in out:
        return jsonify({"error":"invalid_llm_response"}), 502
    nxt = out["next"] or {}
    field = nxt.get("field") or "primary_goal"
    question = nxt.get("question") or "What is your primary business goal (revenue, EBITDA, market share, other)?"
    return jsonify({"analysis_id": session_id, "question": question, "field": field}), 200

@market_iq_bp.route("/intake/answer", methods=["POST"])
def intake_answer():
    p = request.get_json(silent=True) or {}
    sid = p.get("analysis_id")
    ans = (p.get("answer") or "").strip()
    field = (p.get("field") or "").strip() or None
    question = (p.get("question") or "").strip() or None
    if not sid or not ans or not question:
        return jsonify({"error":"analysis_id, question, answer required"}), 400
    if not _session_row(sid):
        return jsonify({"error":"unknown analysis_id"}), 404

    with db() as con:
        con.execute("INSERT INTO qa(session_id, field, question, answer, created_at) VALUES (?,?,?,?,?)",
                    (sid, field, question, ans, datetime.utcnow().isoformat()+"Z"))

    qa_rows = _qa_list(sid)
    missing = _first_missing_fields(qa_rows)

    try:
        out = _chat_json(INTAKE_SYS, {
            "description": _session_row(sid)["description"],
            "qa": qa_rows,
            "required_fields": REQUIRED_FIELDS
        })
    except Exception as e:
        return jsonify({"error":"llm_unavailable", "details": str(e)}), 503

    enough = bool(out.get("enough"))
    # guardrail: if LLM says not enough but we've covered everything, flip to enough
    if not enough and len(missing) == 0:
        enough = True

    if enough:
        # final scoring
        try:
            score_payload = _chat_json(SCORE_SYS, {
                "analysis_id": sid,
                "project_description": _session_row(sid)["description"],
                "qa": qa_rows
            }, temperature=0.1)
            _validate_score(score_payload)
        except Exception as e:
            return jsonify({"error":"scoring_failed", "details": str(e)}), 502
        with db() as con:
            con.execute("UPDATE sessions SET status='scored' WHERE id=?", (sid,))
            con.execute("INSERT OR REPLACE INTO results(session_id, payload_json, created_at) VALUES (?,?,?)",
                        (sid, json.dumps(score_payload), datetime.utcnow().isoformat()+"Z"))
        return jsonify({"complete": True, "analysis_result": score_payload}), 200

    nxt = out.get("next") or {}
    next_field = nxt.get("field") or (missing[0] if missing else "constraints")
    next_q = nxt.get("question") or f"Please provide details for {next_field}."
    return jsonify({"complete": False, "next_field": next_field, "next_question": next_q}), 200

# ---------- Optional: one-shot (kept for compatibility, still real LLM) ----------
@market_iq_bp.route("/analyze", methods=["POST"])
def analyze():
    p = request.get_json(silent=True) or {}
    desc = p.get("description") or p.get("project_description")
    if not desc:
        return jsonify({"error":"description is required"}), 400
    sid = "miq_" + uuid.uuid4().hex[:12]
    with db() as con:
        con.execute("INSERT INTO sessions(id, description, created_at, status) VALUES (?,?,?,?)",
                    (sid, desc, datetime.utcnow().isoformat()+"Z", "intake"))
    qa_rows = p.get("qa") or []
    try:
        score_payload = _chat_json(SCORE_SYS, {"analysis_id": sid, "project_description": desc, "qa": qa_rows}, temperature=0.1)
        _validate_score(score_payload)
    except Exception as e:
        return jsonify({"error":"scoring_failed", "details": str(e)}), 502
    with db() as con:
        con.execute("UPDATE sessions SET status='scored' WHERE id=?", (sid,))
        con.execute("INSERT OR REPLACE INTO results(session_id, payload_json, created_at) VALUES (?,?,?)",
                    (sid, json.dumps(score_payload), datetime.utcnow().isoformat()+"Z"))
    return jsonify(score_payload), 200

# ---------- Deep-dive chat ----------
@market_iq_bp.route("/chat", methods=["POST"])
def chat():
    p = request.get_json(silent=True) or {}
    msg = (p.get("message") or "").strip()
    ctx = p.get("analysis_context") or {}
    if not msg:
        return jsonify({"error":"message is required"}), 400
    client = _get_client()
    if not client:
        return jsonify({"error":"llm_unavailable"}), 503
    sys = ("You are MarketIQ, a pragmatic finance/ops strategist. Answer with crisp, "
           "actionable bullets using the provided analysis context.")
    resp = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL","gpt-4o-mini"),
        temperature=0.3,
        messages=[{"role":"system","content":sys},
                  {"role":"user","content": "Question:\n"+msg+"\n\nAnalysis context:\n"+json.dumps(ctx, ensure_ascii=False)}]
    )
    return jsonify({"response": resp.choices[0].message.content.strip()}), 200

# ---------- Scenario modeling ----------
@market_iq_bp.route("/scenario", methods=["POST"])
def scenario():
    p = request.get_json(silent=True) or {}
    base = p.get("analysis_result") or {}
    changes = p.get("changes") or {}
    if not base:
        return jsonify({"error":"analysis_result required"}), 400
    client = _get_client()
    if not client:
        return jsonify({"error":"llm_unavailable"}), 503
    sys = ("You are MarketIQ-Modeler. Given a base analysis JSON and a set of proposed changes "
           "(e.g., budget +20%, time_to_market -8 weeks), recompute the score and key fields. "
           "Return ONLY JSON with the same schema as scoring plus 'scenario': {changes_applied: string[]} .")
    resp = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL","gpt-4o-mini"),
        temperature=0.2,
        response_format={"type":"json_object"},
        messages=[{"role":"system","content":sys},
                  {"role":"user","content": json.dumps({"base": base, "changes": changes}, ensure_ascii=False)}]
    )
    out = json.loads(resp.choices[0].message.content)
    _validate_score(out)
    out.setdefault("scenario", {"changes_applied":[str(changes)]})
    return jsonify(out), 200
