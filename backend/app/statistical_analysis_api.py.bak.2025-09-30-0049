# statistical_analysis_api.py

import pandas as pd
import numpy as np
import json
import io
import base64
from flask import Blueprint, request, jsonify, current_app
from werkzeug.utils import secure_filename
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import shapiro, normaltest, kstest, anderson
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from openai import OpenAI
import os

# Create blueprint
statistical_bp = Blueprint('statistical_analysis', __name__, url_prefix='/api/statistical-analysis')

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'csv', 'xlsx', 'xls'}

def detect_column_types(df):
    """Detect column types for statistical analysis"""
    column_types = {}
    for col in df.columns:
        if df[col].dtype in ['int64', 'float64']:
            # Check if it's actually categorical (few unique values)
            unique_ratio = df[col].nunique() / len(df)
            if unique_ratio < 0.05 and df[col].nunique() < 20:
                column_types[col] = 'categorical'
            else:
                column_types[col] = 'numeric'
        else:
            column_types[col] = 'categorical'
    return column_types

def get_openai_client():
    """Get OpenAI client with proper configuration"""
    try:
        api_key = current_app.config.get('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OpenAI API key not configured")
        return OpenAI(api_key=api_key)
    except Exception as e:
        raise ValueError(f"Failed to initialize OpenAI client: {str(e)}")

def get_ai_analysis(data_summary, goal, target_col=None, group_col=None):
    """Get AI-powered analysis insights"""
    try:
        client = get_openai_client()
        
        prompt = f"""
        You are a statistical analysis expert. Analyze this dataset and provide insights:
        
        Dataset Summary:
        {data_summary}
        
        Analysis Goal: {goal}
        Target Column: {target_col or 'None specified'}
        Group Column: {group_col or 'None specified'}
        
        Please provide:
        1. Key insights about the data
        2. Recommended statistical tests
        3. Interpretation of results
        4. Next steps for analysis
        
        Keep the response concise and actionable.
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful statistical analysis assistant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"AI analysis unavailable: {str(e)}"

@statistical_bp.route('/upload', methods=['POST'])
def upload_file():
    """Handle file upload and return data preview"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400
    
    if not allowed_file(file.filename):
        return jsonify({'error': 'File type not supported. Please upload CSV or Excel files.'}), 400
    
    try:
        # Read file based on extension
        filename = secure_filename(file.filename)
        if filename.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        
        # Basic info
        column_types = detect_column_types(df)
        
        # Data preview
        preview = {
            'filename': filename,
            'rows': len(df),
            'columns': len(df.columns),
            'column_info': [
                {
                    'name': col,
                    'type': column_types[col],
                    'non_null': int(df[col].count()),
                    'null_count': int(df[col].isnull().sum()),
                    'unique_values': int(df[col].nunique())
                }
                for col in df.columns
            ],
            'sample_data': df.head(5).to_dict('records')
        }
        
        return jsonify({
            'success': True,
            'data': preview,
            'message': f'Successfully loaded {filename} with {len(df)} rows and {len(df.columns)} columns'
        })
        
    except Exception as e:
        return jsonify({'error': f'Error processing file: {str(e)}'}), 500

@statistical_bp.route('/comprehensive', methods=['POST'])
def comprehensive_analysis():
    """Perform comprehensive statistical analysis"""
    try:
        # Get file and goal from request
        file = request.files.get('file')
        goal = request.form.get('goal', 'describe')
        target_col = request.form.get('target_col')
        group_col = request.form.get('group_col')
        
        if not file:
            return jsonify({'error': 'No file provided'}), 400
        
        # Read file
        if file.filename.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        
        column_types = detect_column_types(df)
        numeric_cols = [col for col, dtype in column_types.items() if dtype == 'numeric']
        categorical_cols = [col for col, dtype in column_types.items() if dtype == 'categorical']
        
        results = {
            'dataset_info': {
                'rows': len(df),
                'columns': len(df.columns),
                'numeric_columns': numeric_cols,
                'categorical_columns': categorical_cols
            },
            'analysis': {}
        }
        
        # Descriptive statistics
        if numeric_cols:
            desc_stats = df[numeric_cols].describe().to_dict()
            results['analysis']['descriptive_stats'] = desc_stats
        
        # Correlation analysis
        if len(numeric_cols) > 1:
            corr_matrix = df[numeric_cols].corr().to_dict()
            results['analysis']['correlations'] = corr_matrix
        
        # Group analysis if specified
        if group_col and target_col and group_col in df.columns and target_col in df.columns:
            if column_types.get(target_col) == 'numeric' and column_types.get(group_col) == 'categorical':
                group_stats = df.groupby(group_col)[target_col].agg(['mean', 'std', 'count']).to_dict()
                results['analysis']['group_analysis'] = group_stats
        
        # Get AI insights
        data_summary = f"Dataset with {len(df)} rows, {len(numeric_cols)} numeric columns, {len(categorical_cols)} categorical columns"
        ai_insights = get_ai_analysis(data_summary, goal, target_col, group_col)
        results['ai_insights'] = ai_insights
        
        return jsonify({
            'success': True,
            'results': results
        })
        
    except Exception as e:
        return jsonify({'error': f'Analysis error: {str(e)}'}), 500

@statistical_bp.route('/ai-chat', methods=['POST'])
def ai_chat():
    """Handle AI chat interactions"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        context = data.get('context', {})
        
        if not message:
            return jsonify({'error': 'No message provided'}), 400
        
        client = get_openai_client()
        
        # Build context-aware prompt
        system_prompt = """You are a helpful statistical analysis assistant. You help users understand data analysis, choose appropriate statistical tests, and interpret results. Provide clear, practical advice."""
        
        if context:
            context_info = f"Context: {json.dumps(context, indent=2)}\n\n"
            user_message = context_info + message
        else:
            user_message = message
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=800,
            temperature=0.7
        )
        
        return jsonify({
            'success': True,
            'response': response.choices[0].message.content
        })
        
    except Exception as e:
        return jsonify({'error': f'AI chat error: {str(e)}'}), 500

@statistical_bp.route('/execute-action', methods=['POST'])
def execute_action():
    """Execute suggested statistical actions"""
    try:
        data = request.get_json()
        action = data.get('action', {})
        
        # This would implement specific statistical actions
        # For now, return a placeholder
        return jsonify({
            'success': True,
            'message': 'Action execution not yet implemented',
            'action': action
        })
        
    except Exception as e:
        return jsonify({'error': f'Action execution error: {str(e)}'}), 500

@statistical_bp.route('/test', methods=['GET'])
def test():
    """Test endpoint"""
    return jsonify({
        'message': 'Statistical Analysis API is working',
        'endpoints': [
            '/upload - POST - Upload data file',
            '/comprehensive - POST - Comprehensive analysis',
            '/ai-chat - POST - AI chat assistance',
            '/execute-action - POST - Execute statistical actions'
        ]
    })
